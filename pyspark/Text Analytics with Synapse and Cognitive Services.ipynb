{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Sentiment Analysis with mixed languages on Azure Synapse Analytics\n",
    "\n",
    "This notebook demonstrates the use of cognitive services with mixed languages for sentiment analysis.\n",
    "As Greek is not currently supported for sentiment analysis with the language cognitive service, we use a translator service to first translate Greek to English.\n",
    "\n",
    "This is a Synapse Spark notebook, and should be attached in an Azure Synapse Spark pool to run.\n",
    "As a prerequisite I have provisioned a language and a translator cognitive service, and created two relevant linked services in Synapse, called \"TextAnalytics1\" and \"translator2\":\n",
    "\n",
    "| Translator Service | Language Service |\n",
    "| :-: | :-: |\n",
    "| ![\"translator2\"](img/translator_SynLS.PNG) | ![\"textAnalytics1\"](img/textanalytics2_SynLS.PNG) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2022-03-04T20:50:37.2227849Z",
       "execution_start_time": "2022-03-04T20:50:36.1558253Z",
       "livy_statement_state": "available",
       "queued_time": "2022-03-04T20:47:57.1473724Z",
       "session_id": 15,
       "session_start_time": "2022-03-04T20:47:57.1903618Z",
       "spark_pool": "sparkpool1",
       "state": "finished",
       "statement_id": 1
      },
      "text/plain": [
       "StatementMeta(sparkpool1, 15, 1, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imports and definitions\n",
    "import mmlspark\n",
    "from mmlspark.cognitive import *\n",
    "from notebookutils import mssparkutils\n",
    "from pyspark.sql.functions import col, flatten, arrays_zip, col, explode, expr, lit, concat, array, collect_list\n",
    "\n",
    "#the relevant linked services should have been created in Synapse already\n",
    "translate_service_name = \"translator2\" #translator service\n",
    "sentiment_service_name= \"TextAnalytics1\" #language service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In addition I have uploaded a mock input file (text, tab delimited) on Azure Data Lake, called \"synapse_comments_tab.txt\".\n",
    "This file has a column with mock customer comments, in both English and Greek, called \"comment\" and a \"timestamp\" column as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2022-03-04T20:50:58.0508205Z",
       "execution_start_time": "2022-03-04T20:50:37.3338608Z",
       "livy_statement_state": "available",
       "queued_time": "2022-03-04T20:47:57.1491384Z",
       "session_id": 15,
       "session_start_time": null,
       "spark_pool": "sparkpool1",
       "state": "finished",
       "statement_id": 2
      },
      "text/plain": [
       "StatementMeta(sparkpool1, 15, 2, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read the mock input file into a data frame\n",
    "df = ( spark.read    \n",
    "    .option(\"header\", \"true\")  \n",
    "    .option(\"delimiter\", \"\\t\")\n",
    "    .csv('abfss://matt454-adlfs-eastus@matt454adleastus.dfs.core.windows.net/synapse/workspaces/matt454-synapse-eastus/Raw_Data/synapse_comments_tab.txt')\n",
    ")\n",
    "\n",
    "#reformat the data frame as a single row with arrays of strings to use with translator service\n",
    "df1 = df.agg(collect_list('comment').alias('text'))\n",
    "df2 = df.agg(collect_list('timestamp').alias('timestamp'))\n",
    "detectDF = df1.join(df2,how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Now we can call the translator service. I first detect the language of each comment, so I only translate Greek comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2022-03-04T20:51:06.7837632Z",
       "execution_start_time": "2022-03-04T20:50:58.1788022Z",
       "livy_statement_state": "available",
       "queued_time": "2022-03-04T20:47:57.1510506Z",
       "session_id": 15,
       "session_start_time": null,
       "spark_pool": "sparkpool1",
       "state": "finished",
       "statement_id": 3
      },
      "text/plain": [
       "StatementMeta(sparkpool1, 15, 3, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#translate greek to english\n",
    "\n",
    "## call translator service\n",
    "detect = (Detect()\n",
    "    .setLinkedService(translate_service_name)\n",
    "    .setTextCol(\"text\")\n",
    "    .setOutputCol(\"result\"))\n",
    "\n",
    "## keep original text and detected language\n",
    "df_detected = ( \n",
    "    detect\n",
    "    .transform(detectDF) \n",
    "    .withColumn(\"language\", col(\"result.language\")) \n",
    "    .select(\"text\",\"language\",\"timestamp\") \n",
    "    #and format them into separate rows\n",
    "    .withColumn(\"tmp\", arrays_zip(\"text\", \"language\",\"timestamp\")) \n",
    "    .withColumn(\"tmp\", explode(\"tmp\")) \n",
    "    .select(col(\"tmp.text\"), col(\"tmp.language\"),col(\"tmp.timestamp\")) \n",
    "    )\n",
    "\n",
    "## keep rows in greek to translate to english\n",
    "df_greek= df_detected.where(df_detected.language==\"el\")\n",
    "\n",
    "## keep rows in english and 'translate to english'\n",
    "df_english2english = ( df_detected\n",
    "    .where(df_detected.language==\"en\")\n",
    "    .select(col(\"text\"),col(\"text\").alias(\"translation\"),col(\"timestamp\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Now we send the df_greek dataframe, which contains the Greek records, for translation.\n",
    "Then we concatenate the translated df_greek2english with the df_english2enlish (in which the original English comment was copied as is in the \"translation\" column) to prepare the data frame for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2022-03-04T20:51:13.8991797Z",
       "execution_start_time": "2022-03-04T20:51:06.8910394Z",
       "livy_statement_state": "available",
       "queued_time": "2022-03-04T20:47:57.1531856Z",
       "session_id": 15,
       "session_start_time": null,
       "spark_pool": "sparkpool1",
       "state": "finished",
       "statement_id": 4
      },
      "text/plain": [
       "StatementMeta(sparkpool1, 15, 4, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "translate = (Translate()\n",
    "    .setLinkedService(translate_service_name)\n",
    "    .setTextCol(\"text\")\n",
    "    .setFromLanguage(\"el\")\n",
    "    .setToLanguage([\"en\"])\n",
    "    .setOutputCol(\"translation\")\n",
    "    .setConcurrency(5))\n",
    "## translate greek to english and format\n",
    "df_greek2english = (\n",
    "  translate\n",
    "      .transform(df_greek)\n",
    "      .withColumn(\"translation\", flatten(col(\"translation.translations\")))\n",
    "      .withColumn(\"translation\", col(\"translation.text\"))\n",
    "      #.withColumn(\"translation\",expr(\"substring(translation, 3, length(translation))\"))\n",
    "      .withColumn(\"translation\",explode(\"translation\"))\n",
    "      .select(\"text\",\"translation\",\"timestamp\")\n",
    ")\n",
    "\n",
    "## Union greek and english\n",
    "df_translated = ( df_english2english\n",
    "  .union(df_greek2english)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "We detect the sentiment of the records in df_translated and store the result (original comment, translated comment, sentiment category and timestamp) into a table in the data lake, so we can use it in e.g., Power BI to create reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2022-03-04T20:52:00.1983612Z",
       "execution_start_time": "2022-03-04T20:51:14.0030598Z",
       "livy_statement_state": "available",
       "queued_time": "2022-03-04T20:47:57.1559775Z",
       "session_id": 15,
       "session_start_time": null,
       "spark_pool": "sparkpool1",
       "state": "finished",
       "statement_id": 5
      },
      "text/plain": [
       "StatementMeta(sparkpool1, 15, 5, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sentiment analysis\n",
    "\n",
    "df_translated = ( df_translated\n",
    "    .withColumn(\"lang\",lit(\"EN-US\"))\n",
    ")\n",
    "\n",
    "sentiment = (TextSentiment()\n",
    "    .setLinkedService(sentiment_service_name)\n",
    "    .setTextCol(\"translation\")\n",
    "    .setOutputCol(\"sentiment\")\n",
    "    .setErrorCol(\"error\")\n",
    "    .setLanguageCol(\"lang\"))\n",
    "\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS Sentiment_mockup\")\n",
    "( sentiment\n",
    "    .transform(df_translated)\n",
    "    .select(\"timestamp\",\"text\",\"translation\", col(\"sentiment\")[0]\n",
    "        .getItem(\"sentiment\")\n",
    "        .alias(\"sentiment\"))\n",
    "    .write.format(\"parquet\").saveAsTable('Sentiment_mockup')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2022-03-04T20:52:02.1691387Z",
       "execution_start_time": "2022-03-04T20:52:00.3090222Z",
       "livy_statement_state": "available",
       "queued_time": "2022-03-04T20:47:57.1611846Z",
       "session_id": 15,
       "session_start_time": null,
       "spark_pool": "sparkpool1",
       "state": "finished",
       "statement_id": 6
      },
      "text/plain": [
       "StatementMeta(sparkpool1, 15, 6, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.synapse.widget-view+json": {
       "widget_id": "4e519d81-39f4-41fe-8883-d0b3b694a416",
       "widget_type": "Synapse.DataFrame"
      },
      "text/plain": [
       "SynapseWidget(Synapse.DataFrame, 4e519d81-39f4-41fe-8883-d0b3b694a416)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can easily see the contents of the output table using Spark SQL\n",
    "display(spark.sql(\"select * from Sentiment_mockup\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": null,
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "save_output": true,
  "synapse_widget": {
   "state": {
    "4e519d81-39f4-41fe-8883-d0b3b694a416": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "count",
        "categoryFieldKeys": [
         "0"
        ],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [
         "0"
        ]
       },
       "tableOptions": {},
       "type": "details"
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "1/4/21 18:40",
         "1": "η συσκευασία από τα σουβλάκια που αγόρασα ήταν σκισμένη. Αυτό είναι απαράδεκτο!",
         "2": "the packaging of the skewers I bought was torn. This is unacceptable!",
         "3": "negative"
        },
        {
         "0": "1/5/21 0:10",
         "1": "Δεν παρήγγειλα σουβλάκια μπορείτε να το πάρετε πίσω και να μου στείλετε τη σωστή παραγγελία",
         "2": "I did not order skewers you can take it back and send me the correct order",
         "3": "positive"
        },
        {
         "0": "1/5/21 5:50",
         "1": "Καλά τα σουβλάκια ήταν καταπληκτικά",
         "2": "Well the skewers were amazing",
         "3": "positive"
        },
        {
         "0": "1/5/21 6:30",
         "1": "παρήγγειλα πίτσα με ελιές και δεν υπήρχε καμμία ελιά πάνω",
         "2": "I ordered pizza with olives and there was no olive on top",
         "3": "neutral"
        },
        {
         "0": "1/5/21 11:20",
         "1": "εκτός από πίτσα έχετε και σουβλάκια;",
         "2": "apart from pizza, do you also have skewers?",
         "3": "neutral"
        },
        {
         "0": "1/5/21 14:10",
         "1": "το σουβλάκι με γύρο κοτόπουλο είχε τζατζίκι αντί για σως, δεν μου το είχατε διευκρινήσει",
         "2": "the souvlaki with chicken gyros had tzatziki instead of sauce, you had not specified it to me",
         "3": "neutral"
        },
        {
         "0": "1/6/21 3:50",
         "1": "μου φέρατε λάθος την παραγγελία μου, ήθελα τη σπέσιαλ πίτσα",
         "2": "you brought me the wrong order, I wanted the special pizza",
         "3": "negative"
        },
        {
         "0": "1/6/21 12:30",
         "1": "ήθελα coca cola zero όχι light",
         "2": "I wanted coca cola zero not light",
         "3": "negative"
        },
        {
         "0": "1/6/21 19:30",
         "1": "συγχαρητήρια τα σουβλάκια ήταν καταπληκτικά!",
         "2": "congratulations the skewers were amazing!",
         "3": "positive"
        },
        {
         "0": "1/6/21 22:20",
         "1": "συγχαρητήρια η πίτσα ήταν φοβερή!",
         "2": "congratulations the pizza was awesome!",
         "3": "positive"
        },
        {
         "0": "1/7/21 11:30",
         "1": "η πίτσα ήταν καταπληκτική, τι σως βάζετε;",
         "2": "the pizza was amazing, what sauce do you put on?",
         "3": "positive"
        },
        {
         "0": "1/7/21 15:30",
         "1": "το τρίτο κομμάτι της πίτσας ήταν δαγκωμένο! Σα δε ντρέπεστε!",
         "2": "the third piece of pizza was bitten! You are not ashamed!",
         "3": "mixed"
        },
        {
         "0": "1/7/21 16:40",
         "1": "έλειπε ένα σουβλάκι από την παραγγελία μου",
         "2": "a souvlaki was missing from my order",
         "3": "negative"
        },
        {
         "0": "1/7/21 19:10",
         "1": "το σουβλάκι κοτόπουλο δεν τρωγόταν!",
         "2": "the chicken souvlaki was not eaten!",
         "3": "neutral"
        },
        {
         "0": "1/7/21 23:50",
         "1": "η πίτσα μαργαρίτα δεν είχε σχεδόν καθόλου τυρί, το τσιγκουνεύεστε;",
         "2": "the daisy pizza had almost no cheese, do you skimp on it?",
         "3": "neutral"
        },
        {
         "0": "1/8/21 4:00",
         "1": "η πιο ωραία πίτσα που έχω φάει ποτέ στη ζωή μου!",
         "2": "the most beautiful pizza I've ever eaten in my life!",
         "3": "positive"
        },
        {
         "0": "1/8/21 20:10",
         "1": "φανταστικό σουβλάκι! Μπράβο στον ψήστη!",
         "2": "fantastic souvlaki! Bravo to the roaster!",
         "3": "positive"
        },
        {
         "0": "1/7/21 6:30",
         "1": "my pizza was not as expected",
         "2": "my pizza was not as expected",
         "3": "negative"
        },
        {
         "0": "1/7/21 8:40",
         "1": "this is a disgrace I ordered a vegan pizza and found a piece of sausage in it!",
         "2": "this is a disgrace I ordered a vegan pizza and found a piece of sausage in it!",
         "3": "negative"
        },
        {
         "0": "1/7/21 10:50",
         "1": "what a delightful pizza it was",
         "2": "what a delightful pizza it was",
         "3": "positive"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "timestamp",
         "type": "string"
        },
        {
         "key": "1",
         "name": "text",
         "type": "string"
        },
        {
         "key": "2",
         "name": "translation",
         "type": "string"
        },
        {
         "key": "3",
         "name": "sentiment",
         "type": "string"
        }
       ],
       "truncated": false
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
